# Transformer_architecture_implementation

The goal of this repository is to create an implementation of the Transformer Architecture from scratch as it is described in the [Attention is all you need paper (Google 2017)](https://arxiv.org/pdf/1706.03762)

## Build Status

For the moment, the the project has just begun and is not yet ready to be used.

Throughout the project, if you see any improvements that could be made in the code, do not hesitate to reach out at
Hippolyte.guigon@hec.edu. I will be delighted to get some insights !

## Code style

The all project was coded under PEP-8 (https://peps.python.org/pep-0008/) and flake8 (https://pypi.org/project/flake8/) compliancy. Such compliance is verified during commits with pre-commits file ```.pre-commit-config.yaml```

## Installation

* This project uses a specific conda environment, to get it, run the following command: ```conda env create -f transformer_architecture_environment.yml```

* To install all necessary libraries, run the following code: ```pip install -r requirements.txt```

* This project has its own package that is used. To get it, run the following command: ```python install setup.py```

## Screenshot

![alt text](https://raw.githubusercontent.com/HippolyteGuigon/Transformer_architecture_implementation/main/ressources/transformer_architecture.webp)

Transformer architecture as described in the original paper

## How to use ?